# title:        MULAN: A Blind and Off-Grid Method for Multichannel Echo Retrieval
# authors:      helena.peic.tukuljac@gmail.com, antoine.deleforge@inria.fr
# year:         2018
# license:      GPL v3
# description:  contains methods for loading filters and input signals and measurement preparation in frequency domain
# reference:    uses room impulse responses generated by pyroomacoustics library https://github.com/LCAV/pyroomacoustics

import matplotlib.pyplot as plt
import numpy as np
import os
import pickle
import scipy.signal as signal
from enum import Enum

import logging
logger = logging.getLogger('root')
FORMAT = "[%(filename)s:%(lineno)4s - %(funcName)20s() ] %(message)s"
logging.basicConfig(format=FORMAT)
logger.setLevel(logging.INFO)

### filter types = RIR types
class FilterType(Enum):
    Artificial, Simulation, Experiment = range(3)

### input signal types
class InputSignalType(Enum):
    Artificial, Speech = range(2)

# files and folders for filter
FILTER_FOLDER = 'filter'
SIMULATED_RIR_16000_FOLDER = 'simulation_16000'
SIMULATED_RIR_48000_FOLDER = 'simulation_48000'
EXPERIMENTAL_RIRS = 'experimental_rirs.pkl'

# files and folders for input signal
INPUT_SIGNAL_FOLDER = 'input_signal'
SPEECH_16000_FOLDER = 'speech_16000'
SPEECH_48000_FOLDER = 'speech_48000'
    
def get_measurements(filter_option, input_signal_option, K, Ts, M, F, nF, file_number = 1):
    # load the chosen filter and signal, and compute the measurements
    if(filter_option == FilterType.Simulation):
        filters, alpha, tau = load_simulated_rirs(M, K, F, file_number)
    elif(filter_option == FilterType.Experiment):
        filters, alpha, tau = load_experimental_rirs(M, K)
    else:
        filters, alpha, tau = generate_artificial_rirs(M, K, Ts, F)           
    
    if(input_signal_option == InputSignalType.Speech):
        signal = load_input_signal(Ts, F, file_number)
    else:
        signal = get_artificial_input_signal(Ts, F)          
    
    m, sf, f, frequency_offset, frequency_step, T_total = get_spectral_coefficients(signal, K, filters, nF, F)
    return m, f, frequency_offset, frequency_step, alpha, tau, sf, T_total 

def select_frequency_set(min_freq, max_freq, nF):
    f = np.linspace(min_freq, max_freq, nF)
    offset = f[0]
    step = f[1] - f[0]
    return f, offset, step

def get_spectral_coefficients(s_time, K, filters, nF, F):
    # TIME DOMAIN processing
    Ns = len(s_time)                                   # length of source signal in samples (int)
    Nm = len(s_time) + filters.shape[0] - 1            # length of mic signal in samples (int)
    time_vector_signal = np.linspace(1, Ns, Ns)/F      # time vector for computing ground truth spectrum
    time_vector_convolution = np.linspace(1, Nm, Nm)/F # time vector for computing filter*signal convolution
    T_total = Nm/F
    
    # convolution in time domain
    mic_num = filters.shape[1] 
    m_time = np.zeros((len(time_vector_convolution), mic_num), dtype=np.complex128)    
    for k in range(mic_num):
        m_time[:, k] = signal.convolve(s_time, filters[:, k], 'full')
    
    # FREQUENCY DOMAIN processing
    # we observe the positive frequencies so that we don't have to deal with the DC component
    f, frequency_offset, frequency_step = select_frequency_set(200, 2000, nF)
    s_freq = np.zeros(len(f), dtype=np.complex128)           # ground truth spectrum
    m_freq = np.zeros((len(f), mic_num), dtype=np.complex128)
    for i in range(len(f)): # compute Fourier coefficients at the given set of frequencies
        for k in range(mic_num):
            m_freq[i, k] = 1/T_total*sum(np.multiply(m_time[:, k], np.exp(-1j*2*np.pi*f[i]*time_vector_convolution)))
        s_freq[i] = 1/T_total*sum(np.multiply(s_time, np.exp(-1j*2*np.pi*f[i]*time_vector_signal)))
    
    return m_freq, s_freq, f, frequency_offset, frequency_step, T_total

############################################## FILTERS ##############################################
def generate_artificial_rirs(mic_num, K, T, F): 
    Tf = 0.2*T # we want to ensure that the lenght of the signal is at least 5 time as much as the length of the filter
    # make sure that the measurements from different microphones don't have the same locations up to a shift
    MIN_DIRAC_HEIGHT = 0.3
    MIN_SEPARATION = 0.001
    alpha = np.maximum(np.random.rand(K, mic_num), MIN_DIRAC_HEIGHT)
    delta = np.zeros(mic_num)
    while (min(delta) < MIN_SEPARATION):     # generate new locations until the min_separation is satisfied
        tau = np.random.rand(K, mic_num)*Tf
        tau[0, 0] = 0                        # AMBIGUITY1: there should be one reference Dirac pulse (recostruction up to a shift)
        for i in range(tau.shape[1]):
            a = tau[:, i]
            a.sort
            delta[i] = min([abs(x - y) for x, y in zip(a, np.concatenate((a[1:], a[:1])))])
    # sort all the delays per microphone to make it physically plausible
    for i in range(tau.shape[1]):
        tau[:, i] = np.sort(tau[:, i])
        alpha[0, i] = 1 
    # AMBIGUITY2: we can reconstruct amplitudes up to a scaling factor
    # all of the weights for the direct path signals should be the same                                 
    filters = np.zeros((int(Tf*F), mic_num))
    # filters will have just a few non-zero elements
    for k in range(mic_num):
        for i in range(K):
            filters[int(tau[i, k]*F), k] = alpha[i, k]  
            tau[i, k] = int(tau[i, k]*F)/F
    return filters, alpha, tau   
    
def load_simulated_rirs(M, K, F, file_number):
    file_name = ("%02d-%d" % ((file_number), K)) + '.pkl'
    if(F == 16000):
        with open(os.path.join(FILTER_FOLDER, SIMULATED_RIR_16000_FOLDER, file_name), 'rb') as f: 
            room_dim, alpha, tau, filters = pickle.load(f)
    else:
        with open(os.path.join(FILTER_FOLDER, SIMULATED_RIR_48000_FOLDER, file_name), 'rb') as f: 
            room_dim, alpha, tau, filters = pickle.load(f)
    logger.info('Filter file name: %s', file_name)
    tau = tau[:, 0:M]   
    alpha = alpha[:, 0:M]
    filters = filters[:, 0:M]
    # sort the locations and the weights according to the order of locations
    for i in range(M):
        indices = np.argsort(tau[:, i])
        tau[:, i] = tau[indices, i]
        alpha[:, i] = alpha[indices, i]
    delta = np.zeros((M, 1))
    for i in range(M):
        delta[i] = np.min([abs(tau[:,i] - np.roll(tau[:,i],1)), abs(tau[:,i] - np.roll(tau[:,i],-1))])
    #print("Dirac minimum separation over a channel in ms: \n", (delta*1000).reshape((len(delta),1)))
    return filters, alpha, tau    
    
def load_experimental_rirs(M, K):
    alpha = np.ones((K, M))
    tau = np.zeros((K, M))
    with open(os.path.join(FILTER_FOLDER, EXPERIMENTAL_RIRS), 'rb') as f:
        filters = pickle.load(f)      
    filters = filters[0:int(0.017*48000), :] 
    return filters, alpha, tau   


#################################### INPUT SIGNALS ########################################
def load_input_signal(T, F, file_number):
    from scipy.io import wavfile
    # Load the data and calculate the time of each sample
    file_name = str(file_number) + '.wav'
    if(F == 16000):
        samplerate, data = wavfile.read(os.path.join(INPUT_SIGNAL_FOLDER, SPEECH_16000_FOLDER, file_name))
    else:
        samplerate, data = wavfile.read(os.path.join(INPUT_SIGNAL_FOLDER, SPEECH_48000_FOLDER, file_name))
    logger.info('Signal file name: %s', file_name)
    data = data[0:int(T*F)]
    return data

def get_artificial_input_signal(T, F):
    return np.random.rand(int(T*F))